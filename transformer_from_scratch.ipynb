{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ckqj7h9E7pc"
      },
      "source": [
        "# Assigment 4, Steve Veldman, 7/12/2024\n",
        "(This notebook is part 1, containing my answer to question 1 of this assignment)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 1: 60 points \\\n",
        "Finish Transformer implementation in PyTorch that was left unfinished:\n",
        "* Implement Decoder\n",
        "* Connect Decoder and Encoder\n",
        "* Try to train it on some translation task"
      ],
      "metadata": {
        "id": "jClYksLdFCzp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torch.utils.data import DataLoader\n",
        "#from transformers import AutoTokenizer\n",
        "from torch import nn\n",
        "from transformers import AutoConfig\n",
        "import torch\n",
        "from math import sqrt\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset\n",
        "import torch.optim as optim\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "metadata": {
        "id": "Q3DKDSIUy5mx"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Housekeeping: Import Data, Create Vocabularies and Encodings, Instantiate Dataset/Dataloader:\n",
        "For this problem, I will use the Date Translation dataset that I generated for assignment 1 & 2."
      ],
      "metadata": {
        "id": "Pod9zhirX2zf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Implement Custom \"Pairs\" Class to Capture Data as Pairs for Establishing Vocabulary and Tokens:\n",
        "class Pairs(Dataset):\n",
        "  def __init__(self, data_file):\n",
        "      self.data = pd.read_csv(data_file)\n",
        "\n",
        "  def __len__(self):\n",
        "      return len(self.data)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "      date_numeric = self.data.iloc[idx,0]\n",
        "      date_original = self.data.iloc[idx,1]\n",
        "      return date_original, date_numeric\n",
        "\n",
        "# Load Data as Pairs:\n",
        "train_pairs = Pairs('dates_train.csv')\n",
        "val_pairs = Pairs('dates_val.csv')"
      ],
      "metadata": {
        "id": "4ND7z_-oX2Mk"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_pairs[1][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "ZRxaUBSufYzw",
        "outputId": "77cb4333-2a74-4458-c736-c6fb44bd5d38"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'June 11, 1820'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_pairs[1][1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "pIEWUpR8fcnc",
        "outputId": "c2df5c6c-b0e6-4d89-a175-4e93b48ac779"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1820-06-11'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Vocabularies:\n",
        "numeric_vocab = set()\n",
        "original_vocab = set()\n",
        "\n",
        "for i in range(len(train_pairs)):\n",
        "    numeric_vocab.update(list(train_pairs[i][1]))\n",
        "    original_vocab.update(train_pairs[i][0].split())\n",
        "\n",
        "# Add Start of Sequence Token (\"$\") and End of Sequence Token (\"#\"):\n",
        "numeric_vocab.update([\"$\",\"#\",\"<PAD>\"])\n",
        "original_vocab.update([\"$\",\"#\",\"<PAD>\"])\n",
        "\n",
        "# Creating character/word to token mapping:\n",
        "orig_word2token = {word: i for i, word in enumerate(original_vocab)}\n",
        "num_char2token = {char: i for i, char in enumerate(numeric_vocab)}\n",
        "\n",
        "# Creating token to character/word mapping\n",
        "orig_token2word = {i: word for word, i in orig_word2token.items()}\n",
        "num_token2char = {i: char for char, i in num_char2token.items()}\n",
        "\n",
        "print(\"Numeric vocabulary size:\", len(numeric_vocab))\n",
        "print(\"Original vocabulary size:\", len(original_vocab))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aQG5JM21XxKu",
        "outputId": "f8233e68-45d6-43dd-b3cf-6237898fba40"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Numeric vocabulary size: 14\n",
            "Original vocabulary size: 489\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Implement Custom Dataset Class for Translation:\n",
        "class DateTranslationDataset(Dataset):\n",
        "    def __init__(self, pairs, orig_word2token, num_char2token):\n",
        "        self.pairs = pairs\n",
        "        self.orig_word2token = orig_word2token\n",
        "        self.num_char2token = num_char2token\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.pairs)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        orig, num = self.pairs[idx]\n",
        "        orig_tensor = torch.tensor([self.orig_word2token[word] for word in orig.split()]\n",
        "                                  + [self.orig_word2token['#']], dtype=torch.long)\n",
        "        num_tensor = torch.tensor([self.num_char2token[char] for char in list(num)]\n",
        "                                  + [self.num_char2token['#']], dtype=torch.long)\n",
        "        return orig_tensor, num_tensor"
      ],
      "metadata": {
        "id": "sOpd8HZ3yltP"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create train and test datasets and DataLoader\n",
        "train_dataset = DateTranslationDataset(train_pairs, orig_word2token, num_char2token)\n",
        "val_dataset = DateTranslationDataset(val_pairs, orig_word2token, num_char2token)\n",
        "\n",
        "batch_size = 73\n",
        "translation_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True,  drop_last=True)\n",
        "\n",
        "print(\"Translation samples: \", len(train_dataset))\n",
        "print(\"Translation batches: \", len(translation_dataloader))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6jWz9pCCRlHs",
        "outputId": "fa9fc9da-80d4-4f97-910d-fa0f3fd5c685"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Translation samples:  129356\n",
            "Translation batches:  1772\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "validation_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True,  drop_last=True)"
      ],
      "metadata": {
        "id": "_YJOEK47z0Vx"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Custom Config Parameters:\n",
        "class Config():\n",
        "    def __init__(self, hidden_size, num_attention_heads, num_hidden_layers, input_vocab_size, output_vocab_size):\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_attention_heads = num_attention_heads\n",
        "        self.num_hidden_layers = num_hidden_layers\n",
        "        self.input_vocab_size = input_vocab_size\n",
        "        self.output_vocab_size = output_vocab_size\n",
        "        self.intermediate_size = hidden_size*4\n",
        "        self.hidden_dropout_prob = 0.1\n",
        "        self.input_max_position_embeddings = 5\n",
        "        self.output_max_position_embeddings = 12\n",
        "\n",
        "config = Config(hidden_size=128, num_attention_heads=4, num_hidden_layers=2, input_vocab_size=len(original_vocab), output_vocab_size=len(numeric_vocab))"
      ],
      "metadata": {
        "id": "oAKaopUVoGxY"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xMv53qYXE7pe"
      },
      "source": [
        "## The Encoder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NDKavFXCE7pe"
      },
      "source": [
        "#### Scaled dot-product attention\n",
        "Note: In order to make sure tensor shapes and other outputs were correct, I followed the steps from the example code even when not strictly necessary for defining the functions/classes."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_input(input_date):\n",
        "  input_ids = [orig_word2token[word] for word in input_date.split()]\n",
        "  return torch.tensor(input_ids).unsqueeze(0)"
      ],
      "metadata": {
        "id": "_217CLQnyW8K"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "4NyAYG7GE7pg"
      },
      "outputs": [],
      "source": [
        "input_date = \"June 25, 2024\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids = tokenize_input(input_date)\n",
        "input_ids"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u6jAsA3Eybc4",
        "outputId": "3f445c00-114d-42ce-ab8e-96503fbf9417"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[440, 348, 281]])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YmX2AYjxE7pg",
        "outputId": "1e14387c-c4ab-4797-d231-b34d9d460526"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Embedding(489, 128)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "encoder_token_emb = nn.Embedding(config.input_vocab_size, config.hidden_size)\n",
        "encoder_token_emb"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs_embeds = encoder_token_emb(input_ids)\n",
        "inputs_embeds.size()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iaf7T0vdywUA",
        "outputId": "11d674c9-4b9c-45ee-d592-cb4bda1ee1ae"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 3, 128])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F_jJqPYwE7ph",
        "outputId": "e837e402-915b-443f-eaf2-6c22c26c8b0c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 3, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "query = key = value = inputs_embeds\n",
        "dim_k = key.size(-1)\n",
        "scores = torch.bmm(query, key.transpose(1,2)) / sqrt(dim_k)\n",
        "scores.size()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zLpxpqm0E7ph",
        "outputId": "4ea91093-bdd6-4826-ecdd-0bb7078c6a54"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 1., 1.]], grad_fn=<SumBackward1>)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "weights = F.softmax(scores, dim=-1)\n",
        "weights.sum(dim=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0k2oI59kE7ph",
        "outputId": "6adef91c-8888-4b9b-a5a7-43bad680fe8e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 3, 128])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "attn_outputs = torch.bmm(weights, value)\n",
        "attn_outputs.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "rStDwmS8E7ph"
      },
      "outputs": [],
      "source": [
        "def scaled_dot_product_attention(query, key, value):\n",
        "    dim_k = query.size(-1)\n",
        "    scores = torch.bmm(query, key.transpose(1, 2)) / sqrt(dim_k)\n",
        "    weights = F.softmax(scores, dim=-1)\n",
        "    return torch.bmm(weights, value)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tovL-sfsE7pi"
      },
      "source": [
        "#### Multi-headed attention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "v1qhlG3zE7pi"
      },
      "outputs": [],
      "source": [
        "class AttentionHead(nn.Module):\n",
        "    def __init__(self, embed_dim, head_dim):\n",
        "        super().__init__()\n",
        "        self.q = nn.Linear(embed_dim, head_dim)\n",
        "        self.k = nn.Linear(embed_dim, head_dim)\n",
        "        self.v = nn.Linear(embed_dim, head_dim)\n",
        "\n",
        "    def forward(self, hidden_state):\n",
        "        attn_outputs = scaled_dot_product_attention(\n",
        "            self.q(hidden_state), self.k(hidden_state), self.v(hidden_state))\n",
        "        return attn_outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "USpFxeQhE7pi"
      },
      "outputs": [],
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        embed_dim = config.hidden_size\n",
        "        num_heads = config.num_attention_heads\n",
        "        head_dim = embed_dim // num_heads\n",
        "        self.heads = nn.ModuleList(\n",
        "            [AttentionHead(embed_dim, head_dim) for _ in range(num_heads)]\n",
        "        )\n",
        "        self.output_linear = nn.Linear(embed_dim, embed_dim)\n",
        "\n",
        "    def forward(self, hidden_state):\n",
        "        x = torch.cat([h(hidden_state) for h in self.heads], dim=-1)\n",
        "        x = self.output_linear(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EjK7ABcQE7pi",
        "outputId": "5b6d4e55-b1d2-49e4-8df6-e83720776f95"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 3, 128])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "multihead_attn = MultiHeadAttention(config)\n",
        "attn_output = multihead_attn(inputs_embeds)\n",
        "attn_output.size()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9yVwJcJUE7pi"
      },
      "source": [
        "### The Feed-Forward Layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "dPcZN8HNE7pi"
      },
      "outputs": [],
      "source": [
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.linear_1 = nn.Linear(config.hidden_size, config.intermediate_size)\n",
        "        self.linear_2 = nn.Linear(config.intermediate_size, config.hidden_size)\n",
        "        self.gelu = nn.GELU()\n",
        "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.linear_1(x)\n",
        "        x = self.gelu(x)\n",
        "        x = self.linear_2(x)\n",
        "        x = self.dropout(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t8KBAQH3E7pj",
        "outputId": "e70dfea5-38fa-429d-b772-d5ca6d98246c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 3, 128])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "feed_forward = FeedForward(config)\n",
        "ff_outputs = feed_forward(attn_outputs)\n",
        "ff_outputs.size()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H1zWmZkgE7pj"
      },
      "source": [
        "### Adding Layer Normalization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "adzFexqrE7pj"
      },
      "outputs": [],
      "source": [
        "class TransformerEncoderLayer(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.layer_norm_1 = nn.LayerNorm(config.hidden_size)\n",
        "        self.layer_norm_2 = nn.LayerNorm(config.hidden_size)\n",
        "        self.attention = MultiHeadAttention(config)\n",
        "        self.feed_forward = FeedForward(config)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Apply layer normalization and then copy input into query, key, value\n",
        "        hidden_state = self.layer_norm_1(x)\n",
        "        # Apply attention with a skip connection\n",
        "        x = x + self.attention(hidden_state)\n",
        "        #print(\"Shape of x after self-attention:\", x.shape)\n",
        "        # Apply feed-forward layer with a skip connection\n",
        "        x = x + self.feed_forward(self.layer_norm_2(x))\n",
        "        #print(\"Shape of x after feed-forward:\", x.shape)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cq4pP-GZE7pj",
        "outputId": "c6256685-da28-459b-b7ec-e9449b7e42ea"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([1, 3, 128]), torch.Size([1, 3, 128]))"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "encoder_layer = TransformerEncoderLayer(config)\n",
        "inputs_embeds.shape, encoder_layer(inputs_embeds).size()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NH9BWHo5E7pj"
      },
      "source": [
        "### Positional Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "HuTIu0s3E7pj"
      },
      "outputs": [],
      "source": [
        "class Enc_Embeddings(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.token_embeddings = nn.Embedding(config.input_vocab_size,\n",
        "                                             config.hidden_size)\n",
        "        self.position_embeddings = nn.Embedding(config.input_max_position_embeddings,\n",
        "                                                config.hidden_size)\n",
        "        self.layer_norm = nn.LayerNorm(config.hidden_size, eps=1e-12)\n",
        "        self.dropout = nn.Dropout()\n",
        "\n",
        "    def forward(self, input_ids):\n",
        "        # Create position IDs for input sequence\n",
        "        seq_length = input_ids.size(1)\n",
        "        position_ids = torch.arange(seq_length, dtype=torch.long).unsqueeze(0)\n",
        "        # Create token and position embeddings\n",
        "        token_embeddings = self.token_embeddings(input_ids)\n",
        "        position_embeddings = self.position_embeddings(position_ids)\n",
        "        # Combine token and position embeddings\n",
        "        embeddings = token_embeddings + position_embeddings\n",
        "        embeddings = self.layer_norm(embeddings)\n",
        "        embeddings = self.dropout(embeddings)\n",
        "        return embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kAqyz4paE7pj",
        "outputId": "54cfccb5-66fe-48e1-f9d5-cfbc1a5c4d29"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 3, 128])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "embedding_layer = Enc_Embeddings(config)\n",
        "embedding_layer(input_ids).size()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "3Yi3phEiE7pj"
      },
      "outputs": [],
      "source": [
        "class TransformerEncoder(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.embeddings = Enc_Embeddings(config)\n",
        "        self.layers = nn.ModuleList([TransformerEncoderLayer(config)\n",
        "                                     for _ in range(config.num_hidden_layers)])\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embeddings(x)\n",
        "        for layer in self.layers:\n",
        "            x = layer(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CZp4WABQE7pk",
        "outputId": "82dac12c-0321-403b-a777-7bc85a7f38c0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 3, 128])"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "encoder = TransformerEncoder(config)\n",
        "encoder(input_ids).size()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K7iPxaDyE7pk"
      },
      "source": [
        "## The Decoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tH9lyX8XE7pk",
        "outputId": "7adb426f-f6a5-4d04-bf31-e10245c4216f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [1., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [1., 1., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [1., 1., 1., 1., 0., 0., 0., 0., 0., 0.],\n",
              "        [1., 1., 1., 1., 1., 0., 0., 0., 0., 0.],\n",
              "        [1., 1., 1., 1., 1., 1., 0., 0., 0., 0.],\n",
              "        [1., 1., 1., 1., 1., 1., 1., 0., 0., 0.],\n",
              "        [1., 1., 1., 1., 1., 1., 1., 1., 0., 0.],\n",
              "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 0.],\n",
              "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "#seq_len = input_ids.size(-1)\n",
        "mask = torch.tril(torch.ones(10, 10)).unsqueeze(0)\n",
        "mask[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "kEAAdfbPE7pk"
      },
      "outputs": [],
      "source": [
        "#scores.masked_fill(mask == 0, -float(\"inf\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "hDX2i3hxE7pk"
      },
      "outputs": [],
      "source": [
        "def masked_scaled_dot_product_attention(query, key, value):\n",
        "    dim_k = query.size(-1)\n",
        "    scores = torch.bmm(query, key.transpose(1, 2)) / sqrt(dim_k)\n",
        "    scores = scores.masked_fill(mask == 0, float(\"-inf\"))\n",
        "    weights = F.softmax(scores, dim=-1)\n",
        "    return weights.bmm(value)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MaskedAttentionHead(nn.Module):\n",
        "    def __init__(self, embed_dim, head_dim):\n",
        "        super().__init__()\n",
        "        self.q = nn.Linear(embed_dim, head_dim)\n",
        "        self.k = nn.Linear(embed_dim, head_dim)\n",
        "        self.v = nn.Linear(embed_dim, head_dim)\n",
        "\n",
        "    def forward(self, hidden_state):\n",
        "        attn_outputs = masked_scaled_dot_product_attention(\n",
        "            self.q(hidden_state), self.k(hidden_state), self.v(hidden_state))\n",
        "        return attn_outputs"
      ],
      "metadata": {
        "id": "rVNZ-rpp5NeP"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MaskedMultiHeadAttention(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        embed_dim = config.hidden_size\n",
        "        num_heads = config.num_attention_heads\n",
        "        head_dim = embed_dim // num_heads\n",
        "        self.heads = nn.ModuleList(\n",
        "            [MaskedAttentionHead(embed_dim, head_dim) for _ in range(num_heads)]\n",
        "        )\n",
        "        self.output_linear = nn.Linear(embed_dim, embed_dim)\n",
        "\n",
        "    def forward(self, hidden_state):\n",
        "        x = torch.cat([h(hidden_state) for h in self.heads], dim=-1)\n",
        "        x = self.output_linear(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "6mjw2gpk5Wz2"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CrossAttentionHead(nn.Module):\n",
        "    def __init__(self, embed_dim, head_dim):\n",
        "        super().__init__()\n",
        "        self.q = nn.Linear(embed_dim, head_dim)\n",
        "        self.k = nn.Linear(embed_dim, head_dim)\n",
        "        self.v = nn.Linear(embed_dim, head_dim)\n",
        "\n",
        "    def forward(self, hidden_state, enc_output):\n",
        "        attn_outputs = scaled_dot_product_attention(\n",
        "            self.q(hidden_state), self.k(enc_output), self.v(enc_output))\n",
        "        return attn_outputs"
      ],
      "metadata": {
        "id": "2-3LAPcZCwnC"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadCrossAttention(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        embed_dim = config.hidden_size\n",
        "        num_heads = config.num_attention_heads\n",
        "        head_dim = embed_dim // num_heads\n",
        "        self.heads = nn.ModuleList(\n",
        "            [CrossAttentionHead(embed_dim, head_dim) for _ in range(num_heads)]\n",
        "        )\n",
        "        self.output_linear = nn.Linear(embed_dim, embed_dim)\n",
        "\n",
        "    def forward(self, hidden_state, enc_output):\n",
        "        x = torch.cat([h(hidden_state, enc_output) for h in self.heads], dim=-1)\n",
        "        x = self.output_linear(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "7QGvOylDTxas"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class TransformerDecoderLayer(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.layer_norm_1 = nn.LayerNorm(config.hidden_size)\n",
        "        self.layer_norm_2 = nn.LayerNorm(config.hidden_size)\n",
        "        self.layer_norm_3 = nn.LayerNorm(config.hidden_size)\n",
        "        self.self_attention = MaskedMultiHeadAttention(config)\n",
        "        self.self_enc_dec_attention = MultiHeadCrossAttention(config)\n",
        "        self.feed_forward = FeedForward(config)\n",
        "\n",
        "    def forward(self, x, enc_output):\n",
        "        # Apply layer normalization and then copy input into query, key, value\n",
        "        hidden_state = self.layer_norm_1(x)\n",
        "        # Apply attention with a skip connection\n",
        "        x = x + self.self_attention(hidden_state)\n",
        "        #print(\"Shape of x after self-attention:\", x.shape)\n",
        "        # Apply cross-attention\n",
        "        x = x + self.self_enc_dec_attention(self.layer_norm_2(x), enc_output)\n",
        "        #print(\"Shape of x after cross-attention:\", x.shape)\n",
        "        # Apply feed-forward layer with a skip connection\n",
        "        x = x + self.feed_forward(self.layer_norm_3(x))\n",
        "        #print(\"Shape of x after feed-forward:\", x.shape)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "9NMkv27E_zQ5"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Dec_Embeddings(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.token_embeddings = nn.Embedding(config.output_vocab_size,\n",
        "                                             config.hidden_size)\n",
        "        self.position_embeddings = nn.Embedding(config.output_max_position_embeddings,\n",
        "                                                config.hidden_size)\n",
        "        self.layer_norm = nn.LayerNorm(config.hidden_size, eps=1e-12)\n",
        "        self.dropout = nn.Dropout()\n",
        "\n",
        "    def forward(self, input_ids):\n",
        "        # Create position IDs for input sequence\n",
        "        seq_length = input_ids.size(1)\n",
        "        position_ids = torch.arange(seq_length, dtype=torch.long).unsqueeze(0)\n",
        "        # Create token and position embeddings\n",
        "        token_embeddings = self.token_embeddings(input_ids)\n",
        "        position_embeddings = self.position_embeddings(position_ids)\n",
        "        # Combine token and position embeddings\n",
        "        embeddings = token_embeddings + position_embeddings\n",
        "        embeddings = self.layer_norm(embeddings)\n",
        "        embeddings = self.dropout(embeddings)\n",
        "        return embeddings"
      ],
      "metadata": {
        "id": "gXXgfL06AV2h"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerDecoder(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.embeddings = Dec_Embeddings(config)\n",
        "        self.layers = nn.ModuleList([TransformerDecoderLayer(config)\n",
        "                                     for _ in range(config.num_hidden_layers)])\n",
        "\n",
        "    def forward(self, x, encoder_output):\n",
        "        x = self.embeddings(x)\n",
        "        for layer in self.layers:\n",
        "            x = layer(x, encoder_output)\n",
        "        return x"
      ],
      "metadata": {
        "id": "GYzvv983Bm6H"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerSeq2Seq(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.encoder = TransformerEncoder(config)\n",
        "        self.decoder = TransformerDecoder(config)\n",
        "\n",
        "    def forward(self, encoder_input_ids, decoder_input_ids):\n",
        "        encoder_output = self.encoder(encoder_input_ids)\n",
        "        decoder_output = self.decoder(decoder_input_ids, encoder_output)\n",
        "        return decoder_output\n",
        "\n",
        "    def train_transformer(self, dataloader, optimizer, criterion, epochs=10):\n",
        "      for epoch in range(epochs):\n",
        "        total_loss = 0\n",
        "        for batch_idx, (src, tgt) in enumerate(dataloader):\n",
        "          optimizer.zero_grad()\n",
        "          output = self(src, tgt[:, :-1]) # Exclude last token in target\n",
        "\n",
        "          # Reshape output to [batch_size * seq_len, vocab_size]\n",
        "          output = output.view(-1, output.size(-1))\n",
        "\n",
        "          # Reshape target to [batch_size * seq_len]\n",
        "          tgt = tgt[:, 1:].reshape(-1)\n",
        "\n",
        "          #loss = criterion(output.reshape(-1, output.shape[-1]), tgt[:, 1:].reshape(-1)) # Shift target by one position\n",
        "          loss = criterion(output, tgt)\n",
        "\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "          total_loss += loss.item()\n",
        "        print(f'Epoch {epoch+1}/{epochs}, Loss: {total_loss / len(dataloader)}')"
      ],
      "metadata": {
        "id": "abKhUA0QBRdF"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Instantiate the Transformer and Train:"
      ],
      "metadata": {
        "id": "gUUucYxMY7kZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transformer = TransformerSeq2Seq(config)"
      ],
      "metadata": {
        "id": "cOYcEiimY7EV"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
        "optimizer = optim.Adam(transformer.parameters(), lr=0.0001, betas=(0.9, 0.98), eps=1e-9)\n",
        "\n",
        "transformer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-HFLxHNp2MQA",
        "outputId": "4e14bd1f-d626-4ae7-c45b-37dd8a9d8fbd"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TransformerSeq2Seq(\n",
              "  (encoder): TransformerEncoder(\n",
              "    (embeddings): Enc_Embeddings(\n",
              "      (token_embeddings): Embedding(489, 128)\n",
              "      (position_embeddings): Embedding(5, 128)\n",
              "      (layer_norm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.5, inplace=False)\n",
              "    )\n",
              "    (layers): ModuleList(\n",
              "      (0-1): 2 x TransformerEncoderLayer(\n",
              "        (layer_norm_1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "        (layer_norm_2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "        (attention): MultiHeadAttention(\n",
              "          (heads): ModuleList(\n",
              "            (0-3): 4 x AttentionHead(\n",
              "              (q): Linear(in_features=128, out_features=32, bias=True)\n",
              "              (k): Linear(in_features=128, out_features=32, bias=True)\n",
              "              (v): Linear(in_features=128, out_features=32, bias=True)\n",
              "            )\n",
              "          )\n",
              "          (output_linear): Linear(in_features=128, out_features=128, bias=True)\n",
              "        )\n",
              "        (feed_forward): FeedForward(\n",
              "          (linear_1): Linear(in_features=128, out_features=512, bias=True)\n",
              "          (linear_2): Linear(in_features=512, out_features=128, bias=True)\n",
              "          (gelu): GELU(approximate='none')\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (decoder): TransformerDecoder(\n",
              "    (embeddings): Dec_Embeddings(\n",
              "      (token_embeddings): Embedding(14, 128)\n",
              "      (position_embeddings): Embedding(12, 128)\n",
              "      (layer_norm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.5, inplace=False)\n",
              "    )\n",
              "    (layers): ModuleList(\n",
              "      (0-1): 2 x TransformerDecoderLayer(\n",
              "        (layer_norm_1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "        (layer_norm_2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "        (layer_norm_3): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "        (self_attention): MaskedMultiHeadAttention(\n",
              "          (heads): ModuleList(\n",
              "            (0-3): 4 x MaskedAttentionHead(\n",
              "              (q): Linear(in_features=128, out_features=32, bias=True)\n",
              "              (k): Linear(in_features=128, out_features=32, bias=True)\n",
              "              (v): Linear(in_features=128, out_features=32, bias=True)\n",
              "            )\n",
              "          )\n",
              "          (output_linear): Linear(in_features=128, out_features=128, bias=True)\n",
              "        )\n",
              "        (self_enc_dec_attention): MultiHeadCrossAttention(\n",
              "          (heads): ModuleList(\n",
              "            (0-3): 4 x CrossAttentionHead(\n",
              "              (q): Linear(in_features=128, out_features=32, bias=True)\n",
              "              (k): Linear(in_features=128, out_features=32, bias=True)\n",
              "              (v): Linear(in_features=128, out_features=32, bias=True)\n",
              "            )\n",
              "          )\n",
              "          (output_linear): Linear(in_features=128, out_features=128, bias=True)\n",
              "        )\n",
              "        (feed_forward): FeedForward(\n",
              "          (linear_1): Linear(in_features=128, out_features=512, bias=True)\n",
              "          (linear_2): Linear(in_features=512, out_features=128, bias=True)\n",
              "          (gelu): GELU(approximate='none')\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transformer.train_transformer(translation_dataloader, optimizer, criterion, epochs=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FX1v_wOVU6tN",
        "outputId": "0cd968c2-1481-468f-be19-05ec2f034d04"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5, Loss: 0.7982889625409925\n",
            "Epoch 2/5, Loss: 0.3513216957887193\n",
            "Epoch 3/5, Loss: 0.15056730914255498\n",
            "Epoch 4/5, Loss: 0.06379561357380945\n",
            "Epoch 5/5, Loss: 0.033492572245589596\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transformer.train_transformer(translation_dataloader, optimizer, criterion, epochs=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f3hX2GhM9ula",
        "outputId": "416cae91-f293-436a-f4f5-25177022fce4"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5, Loss: 0.020468875809029192\n",
            "Epoch 2/5, Loss: 0.01398254228972895\n",
            "Epoch 3/5, Loss: 0.010390567351708138\n",
            "Epoch 4/5, Loss: 0.008132720167682144\n",
            "Epoch 5/5, Loss: 0.006571304087526308\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transformer.train_transformer(translation_dataloader, optimizer, criterion, epochs=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jZpzoaRgJ0BZ",
        "outputId": "c400e1a9-8d7a-4fae-92c9-255631f27731"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5, Loss: 0.005512983855026609\n",
            "Epoch 2/5, Loss: 0.004839316803090553\n",
            "Epoch 3/5, Loss: 0.003949055943161322\n",
            "Epoch 4/5, Loss: 0.003743307198947273\n",
            "Epoch 5/5, Loss: 0.003215595563496153\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transformer.train_transformer(translation_dataloader, optimizer, criterion, epochs=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GziFxgr7NnLN",
        "outputId": "eb46393c-5add-4505-b91a-b5a96089c3b1"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5, Loss: 0.0030687263382065265\n",
            "Epoch 2/5, Loss: 0.002789252189441225\n",
            "Epoch 3/5, Loss: 0.0023378077679537482\n",
            "Epoch 4/5, Loss: 0.002250565965013703\n",
            "Epoch 5/5, Loss: 0.002056198958536952\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_and_target(transformer, dataloader):\n",
        "  all_targets = []\n",
        "  all_predictions = []\n",
        "\n",
        "  for batch_idx, (src, tgt) in enumerate(dataloader):\n",
        "    # Use the model to generate predictions\n",
        "    with torch.inference_mode():\n",
        "      output = transformer(src, tgt[:, :-1]) # Exclude last token in target\n",
        "    # Get the predicted token IDs\n",
        "    predicted_ids = torch.argmax(output, dim=-1)\n",
        "\n",
        "    # Convert predicted and target tokens to strings\n",
        "    #targets = [''.join(str(token_id.item()) for token_id in seq) for seq in tgt[:, 1:-1]]\n",
        "    #predictions = [''.join(str(token_id.item()) for token_id in seq) for seq in predicted_ids]\n",
        "\n",
        "    all_targets.extend(tgt[:, 1:-1].tolist())\n",
        "    all_predictions.extend(predicted_ids[:, :-1].tolist())\n",
        "\n",
        "  return all_targets, all_predictions"
      ],
      "metadata": {
        "id": "Ak4chzOYxI-2"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "targets, predictions = predict_and_target(transformer, translation_dataloader)\n",
        "\n",
        "print(targets[:3])\n",
        "print(predictions[:3])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kwK_ZnvncW1F",
        "outputId": "e4693a73-63e5-4e04-c189-f6d11cf0b652"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0, 10, 5, 7, 10, 9, 7, 3, 6], [12, 6, 12, 7, 9, 3, 7, 3, 12], [5, 10, 13, 7, 10, 6, 7, 9, 5]]\n",
            "[[12, 10, 5, 7, 10, 9, 7, 3, 6], [12, 6, 12, 7, 9, 3, 7, 3, 12], [5, 10, 13, 7, 10, 6, 7, 9, 5]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "target_strings = [''.join(map(str, target)) for target in targets]\n",
        "prediction_strings = [''.join(map(str, prediction)) for prediction in predictions]"
      ],
      "metadata": {
        "id": "vAnSSfBUwWWR"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_accuracy = accuracy_score(target_strings, prediction_strings)\n",
        "print(\"Training Accuracy:\", train_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WYnvoGPZwInT",
        "outputId": "0f057907-7c01-45d9-9fec-b0e00b7649f0"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Accuracy: 0.5076146448560561\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_targets, val_predictions = predict_and_target(transformer, validation_dataloader)\n",
        "val_target_strings = [''.join(map(str, target)) for target in val_targets]\n",
        "val_prediction_strings = [''.join(map(str, prediction)) for prediction in val_predictions]\n",
        "\n",
        "val_accuracy = accuracy_score(val_target_strings, val_prediction_strings)\n",
        "print(\"Validation Accuracy:\", val_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uRGAjS4T0Ft6",
        "outputId": "0f8be2c2-bb3f-4bbb-8975-1e9805f16bb4"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy: 0.5109001515198367\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "While the training and test accuracy is currently at ~50%, this calcualtion is being done based on the percentage of dates that it is getting completely correct. From examining a small sample, it looks like the model is consistently getting the majority of these"
      ],
      "metadata": {
        "id": "NahXxEsML9gK"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.17"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}